<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://womeimingzi11.github.io</id>
    <title>洗衣机用户不会用洗衣机</title>
    <updated>2020-04-28T09:15:42.029Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://womeimingzi11.github.io"/>
    <link rel="self" href="https://womeimingzi11.github.io/atom.xml"/>
    <subtitle>Why be a researcher if you can be an Engineer?</subtitle>
    <logo>https://womeimingzi11.github.io/images/avatar.png</logo>
    <icon>https://womeimingzi11.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 洗衣机用户不会用洗衣机</rights>
    <entry>
        <title type="html"><![CDATA[Using R for Everything: 使用 ggplot2 可视化 RDA 结果（I）数据分析与转换]]></title>
        <id>https://womeimingzi11.github.io/post/vY312ek1B/</id>
        <link href="https://womeimingzi11.github.io/post/vY312ek1B/">
        </link>
        <updated>2020-04-28T09:05:16.000Z</updated>
        <content type="html"><![CDATA[<p>关于 RDA（Redundancy analysis 冗余分析）是什么，相信对于已经有可视化需求的同学来说已经不用更多的解释了。</p>
<p>在 R 中常用来进行 RDA 分析和绘制工作的是 <a href="https://cran.r-project.org/web/packages/vegan/vegan.pdf">vegan</a> 和 <a href="https://github.com/gavinsimpson/ggvegan">ggvegan</a> 这两个包。然而，在实际使用中，最常遇到的问题是虽然这些包内建的 plot 等功能可以绘制出基本可用的包，但想要进一步的定制图形却没那么容易。</p>
<p>想要绘制出一副自己满意、编辑满意、导师满意最主要的是审稿人满意的 RDA 结果，作为最强可视化工具之一的 <a href="https://ggplot2.tidyverse.org/">ggplot2</a> 包毋庸置疑是最佳的选择。</p>
<h2 id="我们需要什么样的-rda-图">我们需要什么样的 RDA 图</h2>
<p>首先，我们来思考我们需要什么样的 RDA 图？按照世纪需求以及审稿人的建议：</p>
<blockquote>
<p>I would recommend showing in bold the variables with significant correlations</p>
</blockquote>
<p>笔者最后的目标是绘制一幅：</p>
<pre><code>1. 显示物种信息（实际上是响应变量矩阵）；
2. 环境变量（实际上是解释变量矩阵）；
3. 在两轴上能显示各自的解释度；
4. 标记有显著性的解释变量。
</code></pre>
<p>以笔者对 plot.rda 以及 autoplot.rda 这两个 vegan 和 ggvegan 内建函数的浅薄了解，似乎很难完成。</p>
<h3 id="如何标记有显著性的解释变量">如何「标记有显著性的解释变量」？</h3>
<p>如果进行过 RDA 分析不难发现，使用 vegan 内建的 rda 是没有标记解释变量的显著性的。其实这种显著性需要 vegan 内建的 envfit 函数来得到一个及其近似的结果。通常这个方法在论文中会写作：</p>
<blockquote>
<p>Monte Carlo permutation (999 permutations) was used to identify axes with significant eigenvalues and species-environment correlations.</p>
</blockquote>
<p>由于是进行了 999 次（默认参数可以修改）的蒙特卡洛抽样，因此这个结果是<strong>及其近似</strong>的结果，直接用作 RDA 中解释变量的显著性是没有问题的。然而，envfit 输出的结果并非标准的 data.frame 或者类似的结果，无法方便的输出或者进行分析，后续我们还会进行结果提取的步骤，暂且按下不表。</p>
<h2 id="rda-和-envfit-分析">RDA 和 ENVFIT 分析</h2>
<p>此例，我们使用随机抽取的 150 条土壤线虫群落群落数据以及对应的环境数据，由于不影响后续的理解以及版权考量，对各参数名不再解释。数据可以<a href="https://raw.githubusercontent.com/womeimingzi11/womeimingzi11.github.io/master/rda_data.zip">从此处</a>下载。</p>
<p>每一步的操作以及原因以注释的形式呈现。</p>
<pre><code class="language-R">library('tidyverse')

# read Environmental Variables
df_env &lt;- read_csv('df_env_smp.csv')
# read Community composition matrix
df_com &lt;- read_csv('df_com_smp.csv')

# View the structure of data
head(df_env)
head(df_com)
</code></pre>
<table>
<caption>A tibble: 6 × 13</caption>
<thead>
	<tr><th scope=col>pH</th><th scope=col>MOI</th><th scope=col>TN</th><th scope=col>TP</th><th scope=col>AP</th><th scope=col>NH4</th><th scope=col>NO3</th><th scope=col>SOC</th><th scope=col>MAT</th><th scope=col>MAP</th><th scope=col>PBM</th><th scope=col>PCV</th><th scope=col>PSR</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>-1.6396547</td><td>-0.1610384</td><td>-0.1162406</td><td>-0.44892589</td><td> 0.17966965</td><td> 0.4471754</td><td>-0.5148515</td><td>-0.292278803</td><td> 0.8420221</td><td> 0.02487222</td><td> 0.17638650</td><td> 0.426595458</td><td> 0.2275781</td></tr>
	<tr><td> 0.9429126</td><td>-0.5549069</td><td>-0.7919730</td><td> 0.02952209</td><td>-0.78701735</td><td>-0.3426843</td><td>-0.4197756</td><td>-0.697789311</td><td>-1.5519670</td><td> 0.27013035</td><td>-0.02465146</td><td> 0.008333099</td><td>-0.8352947</td></tr>
	<tr><td>-1.3387571</td><td>-0.2762522</td><td> 0.1998817</td><td>-0.14900328</td><td>-0.10273314</td><td> 0.7179844</td><td>-0.4922144</td><td> 0.461059956</td><td>-0.8480169</td><td> 1.21243154</td><td> 0.73829039</td><td>-0.793336422</td><td> 0.8349340</td></tr>
	<tr><td>-1.2035947</td><td>-0.1658411</td><td>-0.2600847</td><td>-0.45606691</td><td> 0.09277663</td><td>-0.1328073</td><td>-0.1677489</td><td>-0.007572046</td><td> 0.7833595</td><td>-0.87351309</td><td>-0.80968336</td><td>-0.514494850</td><td>-1.2908116</td></tr>
	<tr><td>-1.1762407</td><td> 1.0043821</td><td> 0.2918750</td><td>-0.47748995</td><td> 2.24338416</td><td> 0.7924569</td><td>-0.5827629</td><td> 0.035809220</td><td>-0.2893264</td><td>-0.22471654</td><td> 0.12645186</td><td> 0.182609082</td><td> 0.9867730</td></tr>
	<tr><td> 0.4263991</td><td> 0.5467350</td><td>-0.3570957</td><td>-0.12043922</td><td> 0.54896611</td><td>-0.3652517</td><td>-0.5540892</td><td>-0.360483891</td><td>-0.8480169</td><td> 1.21243154</td><td> 2.11789718</td><td>-0.026522097</td><td> 0.6830950</td></tr>
</tbody>
</table>
<table>
<caption>A tibble: 6 × 5</caption>
<thead>
	<tr><th scope=col>pp</th><th scope=col>ba</th><th scope=col>fu</th><th scope=col>pr</th><th scope=col>om</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>  2.550000</td><td>28.010000</td><td> 2.550000</td><td>2.550000</td><td>15.280000</td></tr>
	<tr><td>  1.311046</td><td> 7.316707</td><td> 1.337884</td><td>1.337884</td><td> 5.953381</td></tr>
	<tr><td>  8.250000</td><td>13.255000</td><td> 3.355000</td><td>0.000000</td><td>14.850000</td></tr>
	<tr><td>102.490000</td><td>18.516667</td><td>20.946667</td><td>0.000000</td><td>23.500000</td></tr>
	<tr><td> 21.350000</td><td>52.720000</td><td>14.846667</td><td>0.000000</td><td> 5.623333</td></tr>
	<tr><td>  2.490000</td><td> 4.965000</td><td> 1.245000</td><td>0.000000</td><td> 2.475000</td></tr>
</tbody>
</table>
<pre><code class="language-R">library('vegan')

# Performing RDA and viewing the results
res_rda &lt;- rda(df_com, df_env)
res_rda

# Performing ENVFIT
res_envfit &lt;- envfit(df_com, df_env)

# However, the result of ENVFIT is not in the data.frame format, we should extract useful information from it.
res_envfit
</code></pre>
<pre><code>Call: rda(X = df_com, Y = df_env)

                Inertia Proportion Rank
Total         2031.7341     1.0000     
Constrained    895.7317     0.4409    5
Unconstrained 1136.0024     0.5591    5
Inertia is variance 

Eigenvalues for constrained axes:
 RDA1  RDA2  RDA3  RDA4  RDA5 
754.0  88.3  45.4   6.2   1.8 

Eigenvalues for unconstrained axes:
  PC1   PC2   PC3   PC4   PC5 
747.4 235.0  96.3  44.7  12.6 





***VECTORS

          pp       ba     r2 Pr(&gt;r)    
pH  -0.94935  0.31421 0.0809  0.002 ** 
MOI  0.79143  0.61126 0.2636  0.001 ***
TN   0.91399  0.40574 0.0887  0.004 ** 
TP   0.86358 -0.50421 0.0002  0.984    
AP   0.99269  0.12071 0.0575  0.025 *  
NH4  0.94495 -0.32722 0.0462  0.036 *  
NO3  0.52786  0.84933 0.1430  0.001 ***
SOC  0.81629  0.57764 0.1440  0.001 ***
MAT  0.10537 -0.99443 0.0118  0.421    
MAP -0.18615 -0.98252 0.0073  0.572    
PBM  0.75360  0.65733 0.0096  0.488    
PCV  0.57508  0.81810 0.0380  0.058 .  
PSR  0.88521 -0.46519 0.0062  0.616    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Permutation: free
Number of permutations: 999
</code></pre>
<p>正如我们在注释提到的，ENVFIT 并不是以 data.frame 的形式提供数据，因此我们还需要通过一些提取的操作才能获得与结果相同的表格。由于这类操作经常使用，因此我们将其包装成 function 并命名为 envfit_to_df</p>
<pre><code class="language-R"># Here, env_obj indicates the result of envfit. In this case, it's the res_envfit.
# r2_dig is the significant figure of R2
# p_dig is the significant figure of p value
envfit_to_df &lt;- function(env_obj,
                         r2_dig = 6,
                         p_dig = 3) {
  r2_fmt &lt;- as.character(paste('%.', r2_dig, 'f', sep = ''))
  p_fmt &lt;- as.character(paste('%.', p_dig, 'f', sep = ''))
  tibble(
      # the name of explainary variables
    factor = names(env_obj$vectors$r),
      # list or vector of R2
    r2 = env_obj$vectors$r,
      # list or vector of p values
    pvals = env_obj$vectors$pvals
  ) %&gt;%
    # generate significant levels by p values
    mutate(sig = case_when(
      pvals &lt;= 0.001 ~ '***',
      pvals &lt;= 0.01 ~ '**',
      pvals &lt;= 0.05 ~ '*',
      TRUE ~ ' '
    )) %&gt;%
    # format the significant figure by format definition before.
    mutate(pvals = sprintf('%.3f', pvals),
           r2 = sprintf(r2_fmt, r2))
}
# Convert result of ENVFIT to data.frame, in fact, it's a tibble.
df_env &lt;- envfit_to_df(res_envfit, r2_dig = 3)
df_env
</code></pre>
<table>
<caption>A tibble: 13 × 4</caption>
<thead>
	<tr><th scope=col>factor</th><th scope=col>r2</th><th scope=col>pvals</th><th scope=col>sig</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><td>pH </td><td>0.081</td><td>0.002</td><td>** </td></tr>
	<tr><td>MOI</td><td>0.264</td><td>0.001</td><td>***</td></tr>
	<tr><td>TN </td><td>0.089</td><td>0.004</td><td>** </td></tr>
	<tr><td>TP </td><td>0.000</td><td>0.984</td><td>   </td></tr>
	<tr><td>AP </td><td>0.058</td><td>0.025</td><td>*  </td></tr>
	<tr><td>NH4</td><td>0.046</td><td>0.036</td><td>*  </td></tr>
	<tr><td>NO3</td><td>0.143</td><td>0.001</td><td>***</td></tr>
	<tr><td>SOC</td><td>0.144</td><td>0.001</td><td>***</td></tr>
	<tr><td>MAT</td><td>0.012</td><td>0.421</td><td>   </td></tr>
	<tr><td>MAP</td><td>0.007</td><td>0.572</td><td>   </td></tr>
	<tr><td>PBM</td><td>0.010</td><td>0.488</td><td>   </td></tr>
	<tr><td>PCV</td><td>0.038</td><td>0.058</td><td>   </td></tr>
	<tr><td>PSR</td><td>0.006</td><td>0.616</td><td>   </td></tr>
</tbody>
</table>
<p>截止到目前，我们已经准备完成了 RDA 分析以及 ENVFIT 分析，并将数据转换成为了满足可视化需求的格式。</p>
<p>最后的可视化会在下一片文章中完成。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[设备管理器中的 MVSI Card Reader USB Device driver 是什么？如何移除其占用盘符？]]></title>
        <id>https://womeimingzi11.github.io/post/she-bei-guan-li-qi-zhong-de-mvsi-card-reader-usb-device-driver-shi-shi-me-ru-he-yi-chu-qi-zhan-yong-pan-fu/</id>
        <link href="https://womeimingzi11.github.io/post/she-bei-guan-li-qi-zhong-de-mvsi-card-reader-usb-device-driver-shi-shi-me-ru-he-yi-chu-qi-zhan-yong-pan-fu/">
        </link>
        <updated>2020-03-23T07:58:19.000Z</updated>
        <content type="html"><![CDATA[<p>最近微电脑添置了一块机械硬盘，毕竟在 SSD 价格飞涨的这个时期里，原本计划一步到位 1T NVME 的计划被腰斩至 512 GB。虽然日常的使用中不会遇到任何问题，但是想要保存一些资料依然有捉襟见肘的局促感。</p>
<p>然而当硬盘安装停当，需要设定盘符之时，却发现盘符编号已经被占用了。原本电脑中的 NVME 硬盘仅一个分区 C 盘，按照预想机械硬盘应该紧接着设定为 D 盘。然而设定菜单中新盘符却只能 E 盘起跳，这说明有一个设备占用了 D 盘。</p>
<figure data-type="image" tabindex="1"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/Snipaste_2020-03-22_21-27-53.png" alt="" loading="lazy"></figure>
<p>然而实际情况是电脑除了一块 NVME 硬盘并没有其他的存储设备。查看设备管理器的磁盘把驱动器组。发现除了 <strong>NVME 硬盘</strong>（HS-SSD-C2000pro 512G 具体产品是海康 C2000 Pro）、<strong>机械硬盘</strong> （HGST XXXX 日立企业硬盘）、<strong>Hyper-V 虚拟硬盘</strong>（Microsoft 虚拟磁盘，这个与本次的讨论无关）之外，还有一个名为 <strong>MVSI Card Reader USB Device driver</strong> 的设备。</p>
<figure data-type="image" tabindex="2"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/Snipaste_2020-03-22_21-29-47.png" alt="Snipaste_2020-03-22_21-29-47" loading="lazy"></figure>
<p>按照设备的名字，大概是一款 USB 读卡器。然而我的机箱本身(TT 启航者 F1 静音版)并没有读卡器，况且我也没有接入其他的 USB 读卡器，莫非是鼠标键盘又抽风了——毕竟曾经遇到过 USB 键鼠插入电脑后无法引导设备的奇葩故障。</p>
<p>不过在尝试插拔键鼠之前，还是决定先把这个 MVSI Card Reader USB Device driver 搜一搜看看是个什么东西。不幸的是搜到的有效结果并不是非常丰富。</p>
<figure data-type="image" tabindex="3"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/Snipaste_2020-03-22_21-31-24.png" alt="Snipaste_2020-03-22_21-31-24" loading="lazy"></figure>
<p>虽然第一个条目似乎是设备的驱动下载，但是点进去就有一股浓浓的不能解决问题的感觉。简介基本上是模式化的内容，并没有设备本身相关的内容。截图也是与文无关的样子，虽然提供了驱动程序下载的链接，但是我并不需要下载驱动呀，Windows 已经帮我装好驱动了，故此先将设备放在一边。</p>
<figure data-type="image" tabindex="4"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/Snipaste_2020-03-22_22-14-33.png" alt="Snipaste_2020-03-22_22-14-33" loading="lazy"></figure>
<p>第二个搜索条目……日语的？先不看了……</p>
<p>第三个搜索条目，欸，JBL Pebbles？虽然页面内并没有出现任何 MVSI 字样，但是巧合的是，我的电脑上也接入了一台 JBL Pebbles USB 音箱。</p>
<p>此时再扫一眼第二条搜索条目，似乎说到了 uaudio0 字样？虽然对于设备 unix 下的访问名称不熟悉——其实插到我的 MBP 下就能查看了，但是谁让我懒呢——不过 audio 大概是音频设备的相关的吧。耐着性子看作者的 Tweet，似乎在说自己的 JBL Pebbles 插入电脑后也会有一个 Removable SCSI 设备，名字也是  MVSI Card Reader USB Device driver。</p>
<figure data-type="image" tabindex="5"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/Snipaste_2020-03-22_21-30-53.png" alt="Snipaste_2020-03-22_21-30-53" loading="lazy"></figure>
<p>考虑到巧合不会同时出现两次（无来源，我现编的），果断拔下 JBL Pebbles，设备管理器中的  MVSI Card Reader USB Device driver 设备消失，在磁盘管理器中也能将机械硬盘设置成为 D 盘了，done！</p>
<figure data-type="image" tabindex="6"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/Snipaste_2020-03-22_22-17-07.png" alt="Snipaste_2020-03-22_22-17-07" loading="lazy"></figure>
<p>事后回想起来，猜测是因为采用 USB 连接电脑的 JBL Pebbles 音箱会采用 USB DAC 的方式来实现工作。但巧合的是这台 USB DAC 还预留了读卡器的接口，虽然 JBL Pebbles 并没有读卡的功能。</p>
<p>不过虽然盘符的问题已经解决了，但是其实还有一个小瑕疵，那就是 Windows Traybar 里面会一直有一个快速移除设备的图标，并且总有一个省略号设备，且无法点击。</p>
<figure data-type="image" tabindex="7"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/Snipaste_2020-03-22_22-09-17.png" alt="Snipaste_2020-03-22_22-09-17" loading="lazy"></figure>
<p>解决方法也很简单，只要从设备管理器中选中 MVSI Card Reader USB Device driver 然后将其禁用即可。目前没有发现副作用。</p>
<figure data-type="image" tabindex="8"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/Snipaste_2020-03-22_22-17-07.png" alt="Snipaste_2020-03-22_22-17-07" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using R for Everything: 使用 ggplot2 可视化新型冠状病毒肺炎在中国的确诊分布]]></title>
        <id>https://womeimingzi11.github.io/post/map_visualization_covid19_by_ggplot2/</id>
        <link href="https://womeimingzi11.github.io/post/map_visualization_covid19_by_ggplot2/">
        </link>
        <updated>2020-03-08T13:36:10.000Z</updated>
        <content type="html"><![CDATA[<p>这篇文章受到 Anisa Dhana 的博文 <a href="https://datascienceplus.com/map-visualization-of-covid19-across-world/">‘Map Visualization of COVID-19 Across<br>
the World with R’</a> 启发，尝试使用 R 语言绘制新冠肺炎 COVID-19 在国内的确诊、治愈和死亡地图。</p>
<h2 id="数据准备">数据准备</h2>
<h3 id="covid-19-data">COVID-19 Data</h3>
<p>绘制地图的第一步是收集数据。</p>
<p>首先，我们感谢约翰霍普金斯 CSSE <a href="https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases">Johns Hopkins CSSE</a>, 他们将全球的疫情数据按照日期制作成了单一的 CSV 文件方便进行各类分析和统计。我们可以从 <a href="https://github.com/CSSEGISandData/COVID-19">Github</a> 页面获得需要的数据。</p>
<p>P.S. 非常建议大家直接使用 read_csv 从源 URL 直接获取数据，这样便于日后维护更新。但是因为个人原因，案例中使用下载至本地的 csv 作为数据源。此操作不影响后续的任务。</p>
<pre><code>library(tidyverse)

# Read the daily CSV file from Jons Hopkins CSSE I highly recommand to read_csv
# from url directly. But for my personal reason I have to download csv and read
# it from local path.

# df_origin &lt;-
# read_csv('http://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-07-2020.csv')
df_origin &lt;- read_csv(&quot;03-07-2020.csv&quot;)

# Replace the slash into underline to make it easyily to filter
names(df_origin) &lt;- names(df_origin) %&gt;% str_replace_all(&quot;/&quot;, &quot;_&quot;)

# Keep the data of mainland and three regions of China
df_cov_china &lt;- filter(df_origin, Country_Region %in% c(&quot;Mainland China&quot;, &quot;Taiwan&quot;, 
    &quot;Hong Kong&quot;, &quot;Macao&quot;))

head(df_cov_china)

## # A tibble: 6 x 8
##   Province_State Country_Region `Last Update`       Confirmed Deaths Recovered
##   &lt;chr&gt;          &lt;chr&gt;          &lt;dttm&gt;                  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;
## 1 Hubei          Mainland China 2020-03-07 11:13:04     67666   2959     43500
## 2 Guangdong      Mainland China 2020-03-07 10:43:02      1352      7      1237
## 3 Henan          Mainland China 2020-03-07 11:23:10      1272     22      1244
## 4 Zhejiang       Mainland China 2020-03-07 09:03:05      1215      1      1154
## 5 Hunan          Mainland China 2020-03-07 09:03:05      1018      4       960
## 6 Anhui          Mainland China 2020-03-06 03:23:06       990      6       979
## # ... with 2 more variables: Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt;
</code></pre>
<h3 id="map-data">Map Data</h3>
<p>我们采用了包含两岸三地、藏南、阿克赛钦以及南海九段线的完整中华人民共和国的行政区划地图。这些数据将会托管在 <a href="https://raw.githubusercontent.com/womeimingzi11/womeimingzi11.github.io/master/mapData.zip">Github</a> 上进行分享，大家可以按需取用。</p>
<pre><code>library(rgdal)

# Read China Admistrative Area data from Shapefile.  To avoid the compatibility
# issue across systems, including Unix-like system and Windows. I highly
# recommand to use the file.path function to create the file paths.
map_cn_area &lt;- file.path(&quot;mapData&quot;, &quot;China_adm_area.shp&quot;) %&gt;% readOGR()

## OGR data source with driver: ESRI Shapefile 
## Source: &quot;C:\Users\chenh\OneDrive\Develop Learn\R\Map Visualization of COVID-19 Across China with R\mapData\China_adm_area.shp&quot;, layer: &quot;China_adm_area&quot;
## with 34 features
## It has 10 fields

# Conver the SpatialPolygonsDataFrame to DataFrame which can be held by ggplot2
df_cn_area &lt;- fortify(map_cn_area)

# Read the names of Province or region, and convert the name from PinYin to
# English.  This can match the Province name between WHO data and map data.
ls_province_name &lt;- map_cn_area@data$ID %&gt;% str_replace(&quot;Xianggang&quot;, &quot;Hong Kong&quot;) %&gt;% 
    str_replace(&quot;Aomen&quot;, &quot;Macao&quot;)

# The id is the unique serial to recongize the different province from map data.
ls_id &lt;- unique(df_cn_area$id)

# The orders of id and province name is all the same, the bind operation will
# combine the province name and id in different data.frame Use Proveince_State to
# Join data from WHO data and map data
df_final &lt;- df_cn_area %&gt;% left_join(bind_cols(Province_State = ls_province_name, 
    id = ls_id)) %&gt;% left_join(df_cov_china, by = &quot;Province_State&quot;)

# Read the boundary of provinces and regions from shapefile, it will be a
# SpatialLinesDataFrame
map_cn_bord &lt;- file.path(&quot;mapData&quot;, &quot;China_adm_bord.shp&quot;) %&gt;% readOGR()

## OGR data source with driver: ESRI Shapefile 
## Source: &quot;C:\Users\chenh\OneDrive\Develop Learn\R\Map Visualization of COVID-19 Across China with R\mapData\China_adm_bord.shp&quot;, layer: &quot;China_adm_bord&quot;
## with 1785 features
## It has 8 fields
## Integer64 fields read as strings:  FNODE_ TNODE_ LPOLY_ RPOLY_ BOU2_4M_ BOU2_4M_ID

df_cn_bord &lt;- fortify(map_cn_bord)
</code></pre>
<h2 id="数据可视化">数据可视化</h2>
<p>当所有的数据准备完成，便可以使用 ggplot2 进行可视化操作。使用 geom_polygon 来绘制不同行政区，因为数据类型是 <code>SpatialPolygonsDataFrame</code> 而使用 geom_path 来绘制行政区的边界，因为数据类型是<code>SpatialLinesDataFrame</code>。</p>
<p>我们需要额外考虑的问题是，因为武汉的患者数量数倍于国内其他区域范围内的患者数量，故此为了能够较为有层次的显示病患数量，我们将数据进行<em>平方根开方</em>处理。</p>
<pre><code>library(ggplot2)
# The group is unique serial of each province and region, in this case, it is
# similar with id.  Use geom_polygon to plot the area part, and use geom_path to
# plot the boundary part.  To make the data can be comparable, the patients in
# Hubei Province are multiple times than those in other provinces and regions,
# the data is root-square transformed.
ggplot() + geom_polygon(aes(x = long, y = lat, group = group, fill = sqrt(Confirmed)), 
    data = df_final) + geom_path(aes(x = long, y = lat, group = group), color = &quot;black&quot;, 
    data = df_cn_bord) + labs(caption = &quot;Data Repository provided by Johns Hopkins CSSE. Visualization by Han Chen&quot;) + 
    guides(fill = guide_legend(title = &quot;确诊人数\n（开平方处理）&quot;)) + theme(text = element_text(color = &quot;#22211d&quot;), 
    plot.background = element_rect(fill = &quot;#ffffff&quot;, color = NA), panel.background = element_rect(fill = &quot;#ffffff&quot;, 
        color = NA), legend.background = element_rect(fill = &quot;#ffffff&quot;, color = NA))
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/mapVisualization_confirmed-1.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using R for Everything: 使用 ggplot2 绘制 RasterLayer 地图]]></title>
        <id>https://womeimingzi11.github.io/post/using-r-for-everything-shi-yong-ggplot2-hui-zhi-rasterlayer-di-tu/</id>
        <link href="https://womeimingzi11.github.io/post/using-r-for-everything-shi-yong-ggplot2-hui-zhi-rasterlayer-di-tu/">
        </link>
        <updated>2020-02-19T12:32:06.000Z</updated>
        <content type="html"><![CDATA[<p>Han (<a href="mailto:chenhan28@gmail.com" class="email">chenhan28@gmail.com</a>)<br>
在最近刚刚完成的一篇 SCI 文章中，为了描述实验的采样范围，通过 ggplot2 包 (Wickham et al. 2019) 将一组 RasterLayer 绘制成为了青藏高原的地形图。考虑到使用 R 绘制地图的中文内容较少，我们进行一次回顾。</p>
<p><strong>PS 因为不是地理方面的文章/专业，所以在专业性方面有欠缺，但对于自然科学类文章中进行展示基本上是足够了。</strong></p>
<h2 id="为什么用-ggplot2-画地图">为什么用 ggplot2 画地图？</h2>
<p><strong>因为我能！（摊手</strong></p>
<p>实际上原因如下：</p>
<ol>
<li>
<p>ggplot2 是非常强大的绘图工具，配合上 ggplot2 的衍生包，这套工具链基本能满足生态学领域几乎所有的绘图需求。</p>
</li>
<li>
<p>如果对 Photoshop 这类图像处理软件熟悉，就会发现使用 ggplot2 画图，逻辑上和 PS 是非常相似的，便于快速上手和修改生成的图像——天知道把英文图改成中文图有多烦人</p>
</li>
<li>
<p>此外相比于 ArcGIS 这类软件 R 这类跨平台软件几乎可以在任何环境下完成绘图任务，甚至可以在家中的机顶盒安装 R，只不过慢到天长地久而已。</p>
</li>
<li>
<p>免费免费免费</p>
</li>
</ol>
<p>在开始之前，先来看看最终的展示效果。<strong>为了避免文章版权和数据共享问题，地图上样点均去除，仅供参考。</strong></p>
<figure data-type="image" tabindex="1"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/gmap.jpg" alt="Demo without points" loading="lazy"></figure>
<h2 id="什么是-rasterlayer">什么是 RasterLayer？</h2>
<p>关于 RasterLayer 的定义，在 <a href="https://rspatial.org/raster/spatial/4-rasterdata.html">Spatial Data Science (Feed the Future n.d.)</a> 中有很好的解释。</p>
<blockquote>
<p>A RasterLayer object represents single-layer (variable) raster data. A<br>
RasterLayer object always stores a number of fundamental parameters<br>
that describe it. These include the number of columns and rows, the<br>
spatial extent, and the Coordinate Reference System. In addition, a<br>
RasterLayer can store information about the file in which the raster<br>
cell values are stored (if there is such a file). A RasterLayer can<br>
also hold the raster cell values in memory.</p>
</blockquote>
<p>在 R 中提及的 RasterLayer 通常指的是由 sp 包 (Pebesma et al. 2019) 提供的 RasterLayer 类，每一个 RasterLayer 代表一层 raster 栅格数据，其中记录了 raster 数据的基础信息，例如行、列、空间范围、参考系。而对 RasterLayer 进行操作最常用的工具是 raster 包 (Hijmans et al. 2020)。</p>
<h2 id="数据准备">数据准备</h2>
<p>所需加载包： 1. <code>elevatr</code>(Hollister and Shah 2018)；2. <code>raster</code>； 3.<code>tidyverse</code> (Wickham and RStudio 2019)</p>
<p>具体到这一次的地图绘制中，我们需要<strong>两个</strong> RasterLayer —— 1. 作为背景层的 <code>bg_rst</code>，以及 2.用作展示地形的 <code>tp_rst</code>。那么如何获得这两个 RasterLayer 呢？<code>elevatr</code> 包提供了专门用于获取高程栅格数据的方法 <code>get_elev_raster</code>.</p>
<p>不过在获取高程数据之前，需要首先指定地图绘制矩形边界。之后方可使用 <code>get_elev_raster</code> 来获取边界范围内的高程数据，使用 <code>z</code> 参数 (zoom) 确定缩放程度。因为通过 <code>get_elev_raster</code> 获取高程 raster 的方法是获取服务器与自定义边界的最小公倍数（不准确的说法），所以需要对获取的原始 RasterLayer 再次剪切，以便得到地图绘制矩形边界内的数据。</p>
<pre><code class="language-r">library(elevatr)  # Get rasterlay from AWS by `get_elev_raster` fucntion
library(raster)  # Manipulate RasterLayer object
library(tidyverse)  # Tidy is everything.

# Set the extent we want to plot
ext_sample &lt;- extent(70, 105, 25, 45)

# Preparing for getting the elevation raster data, make a blank RasterLayer,
# becasue the first parameter of get_elev_raster is a target Rasterlayer.
bg_init &lt;- raster(ext = ext_sample, resolution = 0.01)
# Get elevation raster with zoom 5, then only keep the extend we want to plot
# later.
bg_rst &lt;- get_elev_raster(bg_init, z = 5) %&gt;% crop(ext_sample)
</code></pre>
<p><code>bg_rst</code> 就是地图背景中灰色的辅助部分的数据就准备好了。</p>
<pre><code class="language-r"># Let's check the detail of bg_rst, the Background RasterLayer
bg_rst
</code></pre>
<pre><code>## class      : RasterLayer 
## dimensions : 1075, 1591, 1710325  (nrow, ncol, ncell)
## resolution : 0.022, 0.0186  (x, y)
## extent     : 70.008, 105.01, 25.0029, 44.9979  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 
## source     : /private/var/folders/0s/pkk0623j6dgdq9yyg4d3qtq40000gn/T/RtmpUCKkKF/raster/r_tmp_2020-02-21_223346_8889_78742.grd 
## names      : layer 
## values     : -156.1392, 8006.811  (min, max)
</code></pre>
<p>随后我们需要下载青藏高原的多边形文件，这里我们选择张镱锂 (2002) 等人在《论青藏高原范围与面积》一文提供的青藏高原范围与界线地理信息系统数据。从<a href="http://www.geodoi.ac.cn/WebCn/doi.aspx?Id=135">《全球变化科学研究数据出版系统》</a>下载即可。这里我选择了 <code>DBATP.zip</code> 下载，对应的文件格式为 Shaplefile，使用 rgdal 包 (Bivand et al. 2019) 提供的 <code>readOGR</code> 方法读取其中的 <code>DBATP_Polygon.shp</code>，保存的数据类型为<code>tp_ext</code>（类型为 SpatialPolygonsDataFrame）。之后将<code>bg_rst</code> 数据按照 <code>tp_ext</code> 形状进行处理，获得符合青藏高原范围的 RasterLayer <code>tp_rst</code>。</p>
<pre><code class="language-r">library(rgdal)
# Read the SpatialPolygon File from DBATP_Polygon.shp
tp_ext &lt;- readOGR(&quot;DBATP/DBATP_Polygon.shp&quot;)
</code></pre>
<pre><code>## OGR data source with driver: ESRI Shapefile 
## Source: &quot;/Users/chenhan/Documents/Develop Learn/R/plotMapByGGplot/DBATP/DBATP_Polygon.shp&quot;, layer: &quot;DBATP_Polygon&quot;
## with 1 features
## It has 1 fields
</code></pre>
<pre><code class="language-r"># Keep the shpae of the Tibetan Plateau
tp_rst &lt;- mask(bg_rst, tp_ext)
</code></pre>
<p>为了便于定位，我们还将在图片上绘制地标名称 <code>city_ls</code>，以及采样点位置及其类型 <code>hbt_coord</code>。</p>
<p>PS.可以根据自己的实际情况确定数据的存储类型，这里因为个人项目的实际情况，数据并没有保存成为常见的 data.freame 或者 tibble 之类的类表格形式。<strong>注意绘图过程中前后对应即可</strong>。</p>
<pre><code class="language-r"># Create the list of landmarks which we want to mark
city_ls &lt;- list(x = c(91.1, 86.925278, 101.7781), y = c(29.65, 27.988056, 36.6169), 
    label = c(&quot;Lhasa&quot;, &quot;Qomolangma&quot;, &quot;Xi'Ning&quot;))
str(city_ls)
</code></pre>
<pre><code>## List of 3
##  $ x    : num [1:3] 91.1 86.9 101.8
##  $ y    : num [1:3] 29.6 28 36.6
##  $ label: chr [1:3] &quot;Lhasa&quot; &quot;Qomolangma&quot; &quot;Xi'Ning&quot;
</code></pre>
<pre><code class="language-r"># Read point with latitude and longitude. This operation is not needed for
# everyone, actually it depends on the actual data structure.
hbt_coord &lt;- read_rds(&quot;hbt_coord.rds&quot;) %&gt;% mutate(Ecosystem = ifelse(hbt == &quot;M&quot;, 
    &quot;Alpine Meadow&quot;, &quot;Alpine Steppe&quot;))
str(hbt_coord)
</code></pre>
<pre><code>## Classes 'tbl_df', 'tbl' and 'data.frame':    432 obs. of  4 variables:
##  $ hbt      : chr  &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; ...
##  $ lon      : num  101 101 101 100 100 ...
##  $ lat      : num  35.3 35 35 34.5 34.5 ...
##  $ Ecosystem: chr  &quot;Alpine Meadow&quot; &quot;Alpine Meadow&quot; &quot;Alpine Meadow&quot; &quot;Alpine Meadow&quot; ...
</code></pre>
<p><strong>注意</strong>，前面的操作中，我们裁剪 RasterLayer 用到了 crop 和 mask 两种操作，关于这两种操作的解释，我用一张图来解释：</p>
<figure data-type="image" tabindex="2"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/JPEG%E5%9B%BE%E5%83%8F-606FC26ACE54-1.jpeg" alt="Differences between crop andmask" loading="lazy"></figure>
<p>简而言之，两种操作都会得到更小的矩形图形，但是使用 mask 方法会在多边形区域外的矩形部分填充 NA 使被裁剪 RasterLayer 看起来成为多边形。</p>
<h2 id="地图绘制">地图绘制</h2>
<p>所需加载包： <code>scales</code> (Wickham, Seidel, and RStudio 2019)</p>
<p>不过在进行绘图之前，还需要对 RasterLayer 数据进行一些小的调整，以便与 <code>ggplot2</code> 的功能兼容。首先将两个 RasterLayer 转换为 data.frame 保留 xy，xy 为经纬度，应点上的值将会保留成与 RasterLayer 中 names 相同的列名，比如 <code>bg_rst</code> 转换为 data.frame 后列名就是 x, y, layer。之后我们将 layer（在此处为当前为止的海拔高度）转换数值范围，因为保留原始的数据用作后面的透明度会让整张图像灰蒙蒙。</p>
<p>不过要注意的是，正如我们前面说到的 mask 后的 RasterLayer 会将区域外的数据标记为 NA，如果直接使用 NA 绘图将会出现各种奇怪的效果，因此我们选择将 NA 数据更换为 0，将区域内的数据更换为 1，将两种值用作图像的 alpha 就会绘制出准确的青藏高原样式。</p>
<p>没看懂咋办？呆胶布！动手试试不进行 NA 转换的效果便知道了。</p>
<pre><code class="language-r"># scales package provide rescale function which can convert the range of numbers
# list to another range.
library(scales)
</code></pre>
<pre><code>## 
## Attaching package: 'scales'

## The following object is masked from 'package:purrr':
## 
##     discard

## The following object is masked from 'package:readr':
## 
##     col_factor
</code></pre>
<pre><code class="language-r"># First convert RasterLayer as Data.Frame with xy coordinate system.  Then
# rescale the elevaion to alpha, as the background part, super high alpha value
# is not a good idea, which range is the best? It depends by the actual. Save the
# alpha value with colname 'alpha'
bg_rst_df &lt;- as.data.frame(bg_rst, xy = TRUE) %&gt;% mutate(alpha = rescale(layer, to = c(0.25, 
    0.75)))

# NA will be generated by the mask function, if use NA and evelation as the alpha
# of Topographic figure, it will be dizzy, and for color Topographic figure
# please don't use the greyscale and color for the evelation simultaneously. Just
# use alpha to control the shape of regional shpae.
tp_rst_df &lt;- as.data.frame(tp_rst, xy = TRUE) %&gt;% mutate(alpha = ifelse(is.na(layer), 
    0, 1))
</code></pre>
<p>当数据准备完毕，我们就开始图形的绘制。首先进行地形图叠加到背景地形的绘制。因为命令较多，并且均以注释的形式标注到代码中，故此不再提前讲解。</p>
<pre><code class="language-r"># sacle_parm as a parameter controls the sclae of the hole figure, it will be
# used to control the size of text, point, legend, etc. to fit the size of
# figure.
scale_parm &lt;- 2
# Init ggplot
gmap &lt;- ggplot() + # plot the backgroun layer, set the alpha without color will make a grey
# background
geom_raster(data = bg_rst_df, aes(x = x, y = y, alpha = alpha)) + # plot the topographic layer, set alpha to keep the shape of Tibetan Plateau
# (TP). Color indicates the elevation.
geom_raster(data = tp_rst_df, aes(x = x, y = y, fill = layer, alpha = alpha)) + # terrain.colors is an built-in function to generate a list of color palettes.
# set the legend title of evelation by name parameter.
scale_fill_gradientn(colours = terrain.colors(100), name = &quot;Elevation (m)&quot;) + # As we said before, the alphas is used to determine the shpae of TP, we don't
# need to show them as legends.
scale_alpha(guide = &quot;none&quot;) + # Project this figure as a map but not a normal figure
coord_quickmap() + # Set preset theme makes things easire
theme_minimal() + # Set the limititions of axes. `expand` parameter will remove the gaps between
# the rectangle map and axes.  If you are not sure what's this mean, remove the
# parameter by yourself and you will find it out.
scale_x_continuous(limits = c(70, 105), expand = c(0, 0)) + scale_y_continuous(limits = c(25, 
    45), expand = c(0, 0)) + # Set the titles of axis
labs(x = &quot;Longtitude (E)&quot;, y = &quot;Laitude (N)&quot;) + # remove the background color and background grid, you know the classical
# ggplot's grid, don't you?
theme(panel.grid = element_blank(), panel.background = element_blank()) + # Set the size of axis and legend
theme(axis.title = element_text(size = 7 * scale_parm), axis.text = element_text(size = 6 * 
    scale_parm)) + theme(legend.key.width = unit(0.2 * scale_parm, &quot;cm&quot;), legend.key.height = unit(0.5 * 
    scale_parm, &quot;cm&quot;), legend.text = element_text(size = 5 * scale_parm), legend.title = element_text(size = 6 * 
    scale_parm))

# Preview will slow down the process of operations, I highly recommand do not
# preveiw the ggplot and save it as a file directly.
</code></pre>
<p>上述操作完毕，如果没有意外，就可以获得一张效果尚可的底图了。但是，个人强烈建议不进行预览图像，直接进行后续的操作，因为绘制当前精度的底图需要花费较长的时间。或者可以使用 <code>ggsave</code> 方法输出为文件进行预览，这样如果效果满意，可以直接用作成品，避免预览后再次绘制效率较低。</p>
<p>随后我们再将地标为止添加到底图上。</p>
<pre><code class="language-r">gmap &lt;- gmap +
  # Add the city_ls to the main plot as landmarks.
  geom_text(
    mapping = aes(x = x, y = y, label = label),
    # geom_text don't support the structure we used. 
    # convert the list into data.frame, every element is used as column here.
    data = bind_cols(city_ls),
    size = 2 * scale_parm
  )
</code></pre>
<p>最后将采样点添加到底图上。注意 ⚠️ 由于版权和数据分享的原因，我将采样点的坐标设置为 0，0，故此图片上不会显示任何采样点，请根据实际情况设置！</p>
<pre><code class="language-r">gmap &lt;- gmap +
  # Add the sample sites to the main plot as points.
  # Due to the copyright of my scholar article and data share policy, I won't point my sample sites to the picuture, the coordinations of point is 0,0 here.
  geom_point(
    mapping = aes(
      # x = lon,
      x = 0,
      y = 0,
      # y = lat,
      col = Ecosystem,
      shape = Ecosystem
    ),
    data = hbt_coord,
    # Don't set the size as 0 until you don't want to see anything here.
    # Don't set the size as 0 until you don't want to see anything here.
    # Don't set the size as 0 until you don't want to see anything here.
    size = 0 * scale_parm
  ) +
  # Convert the color as legend class, becasuse the shape legend is legend class.
  # If there is no class conversion, the shape and color will be showed as two legends.
  # Then select colour as guides and site a larger size to make it more readable.
  # Don't know what's these means? Commit below code will show you everything.
  scale_color_discrete(guide = &quot;legend&quot;) +
  guides(colour = guide_legend(override.aes = list(size = .8 * scale_parm)))
</code></pre>
<p>如果对输出结果满意，那么可以跳过下面这一步，直接进行 <code>ggsave</code> 操作保存图像。不过在这里，保存图像之前，我们还需要修改图片的空白区域 margins 来让图像更合适一些。</p>
<pre><code class="language-r">gmap &lt;- gmap +
  theme(plot.margin =
          # Set marigns of figure, the order of parameters is top, right, bottom, left
          unit(
            c(0 * scale_parm, 0 * scale_parm, -.2 * scale_parm, .2 * scale_parm),
            &quot;cm&quot;
          ))
</code></pre>
<p>最后导出图像即可。<code>ggsvae</code> 提供了丰富的参数定义输出的图像。对于需要投稿 SCI 的文章，通常 Author Guidelines 要求提供不低于 300 DPI 的图片文件。如果允许，保存为 PDF 文件会是不错的方法，毕竟通用性和文件大小都能得到很好的满足。</p>
<pre><code class="language-r">ggsave(filename = &quot;gmap.pdf&quot;, plot = gmap, width = 9 * scale_parm, height = 6.2 * 
    scale_parm, units = &quot;cm&quot;, dpi = 600)
</code></pre>
<pre><code>## Warning: Removed 432 rows containing missing values (geom_point).
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://picgo-1256649726.cos.ap-chengdu.myqcloud.com/gmap.jpg" alt="" loading="lazy"></figure>
<p>最后，如果有任何更好的意见和建议，换用通过任何形式与我交流。祝大家都能制作出令自己（主要是杂志）满意的作品。</p>
<h2 id="参考文献">参考文献</h2>
<div id="refs" class="references hanging-indent" markdown="1">
<div id="ref-bivand_rgdal_2019" markdown="1">
<p>Bivand, Roger, Tim Keitt, Barry Rowlingson, Edzer Pebesma, Michael Sumner, Robert Hijmans, Even Rouault, Frank Warmerdam, Jeroen Ooms, and Colin Rundel. 2019. “Rgdal: Bindings for the ’Geospatial’ Data Abstraction Library.” <a href="https://CRAN.R-project.org/package=rgdal">https://CRAN.R-project.org/package=rgdal</a>.</p>
</div>
<div id="ref-feed_the_future_raster_nodate" markdown="1">
<p>Feed the Future. n.d. “Raster Data — R Spatial.” Blog. <em>Spatial Data Science</em>. Accessed February 19, 2020. <a href="https://rspatial.org/raster/spatial/4-rasterdata.html">https://rspatial.org/raster/spatial/4-rasterdata.html</a>.</p>
</div>
<div id="ref-hijmans_raster_2020" markdown="1">
<p>Hijmans, Robert J., Jacob van Etten, Michael Sumner, Joe Cheng, Andrew Bevan, Roger Bivand, Lorenzo Busetto, et al. 2020. “Raster: Geographic Data Analysis and Modeling.” <a href="https://CRAN.R-project.org/package=raster">https://CRAN.R-project.org/package=raster</a>.</p>
</div>
<div id="ref-hollister_elevatr_2018" markdown="1">
<p>Hollister, Jeffrey, and Tarak Shah. 2018. “Elevatr: Access Elevation Data from Various APIs.” <a href="https://github.com/jhollist/elevatr">https://github.com/jhollist/elevatr</a>.</p>
</div>
<div id="ref-pebesma_sp_2019" markdown="1">
<p>Pebesma, Edzer, Roger Bivand, Barry Rowlingson, Virgilio Gomez-Rubio, Robert Hijmans, Michael Sumner, Don MacQueen, Jim Lemon, Josh O’Brien, and Joseph O’Rourke. 2019. “Sp: Classes and Methods for Spatial Data.” <a href="https://CRAN.R-project.org/package=sp">https://CRAN.R-project.org/package=sp</a>.</p>
</div>
<div id="ref-wickham_ggplot2_2019" markdown="1">
<p>Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and RStudio. 1.    “Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics.” <a href="https://CRAN.R-project.org/package=ggplot2">https://CRAN.R-project.org/package=ggplot2</a>.</p>
</div>
<div id="ref-wickham_tidyverse_2019" markdown="1">
<p>Wickham, Hadley, and RStudio. 2019. “Tidyverse: Easily Install and Load<br>
the ’Tidyverse’.” <a href="https://CRAN.R-project.org/package=tidyverse">https://CRAN.R-project.org/package=tidyverse</a>.</p>
</div>
<div id="ref-wickham_scales_2019" markdown="1">
<p>Wickham, Hadley, Dana Seidel, and RStudio. 2019. “Scales: Scale Functions for Visualization.” <a href="https://CRAN.R-project.org/package=scales">https://CRAN.R-project.org/package=scales</a>.</p>
</div>
<div id="ref-__2002" markdown="1">
<p>张镱锂, 李炳元, and 郑度. 2002. “论青藏高原范围与面积.” <em>地理学报</em> 21 (1): 1–8. <a href="https://doi.org/10.11821/yj2002010001">https://doi.org/10.11821/yj2002010001</a>.</p>
</div>
</div>]]></content>
    </entry>
</feed>